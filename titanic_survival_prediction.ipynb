{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Description: This program predicts if a passenger will survive on the titanic\n",
    "#\n",
    "#Resources: https://towardsdatascience.com/predicting-the-survival-of-titanic-passengers-30870ccc7e8\n",
    "#           http://campus.lakeforest.edu/frank/FILES/MLFfiles/Bio150/Titanic/TitanicMETA.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "titanic = sns.load_dataset('titanic')\n",
    "#Print the first 10 rows of data\n",
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of rows and columns in the data set\n",
    "titanic.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get some statistics from our data set, count, mean standard deviation etc.\n",
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a count of the number of survivors \n",
    "titanic['survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the count of number of survivors\n",
    "sns.countplot(titanic['survived'],label=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the count of survivors for columns 'who', 'sex', 'pclass', 'sibsp', 'parch', and 'embarked'\n",
    "cols = ['who', 'sex', 'pclass', 'sibsp', 'parch', 'embarked']\n",
    "\n",
    "n_rows = 2\n",
    "n_cols = 3\n",
    "\n",
    "#Number of rows/columns of the subplot grid and the figure size of each graph\n",
    "#NOTE: This returns a Figure (fig) and an Axes Object (axs)\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols*3.2,n_rows*3.2))\n",
    "\n",
    "for r in range(0,n_rows):\n",
    "    for c in range(0,n_cols):  \n",
    "        \n",
    "        i = r*n_cols+ c #index to go through the number of columns       \n",
    "        ax = axs[r][c] #Show where to position each subplot\n",
    "        sns.countplot(titanic[cols[i]], hue=titanic[\"survived\"], ax=ax)\n",
    "        ax.set_title(cols[i])\n",
    "        ax.legend(title=\"survived\", loc='upper right') \n",
    "        \n",
    "plt.tight_layout()   #tight_layout automatically adjusts subplot params so that the subplot(s) fits in to the figure area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at survival rate by sex\n",
    "titanic.groupby('sex')[['survived']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at survival rate by sex and class\n",
    "titanic.pivot_table('survived', index='sex', columns='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at survival rate by sex and class visually\n",
    "titanic.pivot_table('survived', index='sex', columns='class').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the survival rate of each class.\n",
    "sns.barplot(x='class', y='survived', data=titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at survival rate by sex, age and class\n",
    "age = pd.cut(titanic['age'], [0, 18, 80])\n",
    "titanic.pivot_table('survived', ['sex', age], 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the Prices Paid Of Each Class\n",
    "plt.scatter(titanic['fare'], titanic['class'],  color = 'purple', label='Passenger Paid')\n",
    "plt.ylabel('Class')\n",
    "plt.xlabel('Price / Fare')\n",
    "plt.title('Price Of Each Class')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the empty (NaN, NAN, na) values in each column\n",
    "titanic.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at all of the values in each column & get a count\n",
    "for val in titanic:\n",
    "  print(titanic[val].value_counts())\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROP REDUNDENT COLUMNS & REMOVE EMPTY ROWS\n",
    "#embark_town = embarked\n",
    "#alive = survived\n",
    "#class = pclass\n",
    "\n",
    "#alone = (sibsp or parch) meaning if you have siblings/spouses or parents/children on board than you are not alone else you are\n",
    "#adult_male = (male and age >= 18) meaning if you are a male age 18 or older than true else false, same goes for the who column which tracks only adult males, adult females, and children\n",
    "#who = (Males age >= 18, Females age >= 18, children age < 18)\n",
    "\n",
    "#deck missing 688 / 891 = 77.22% of the data\n",
    "\n",
    "\n",
    "\n",
    "# Drop / remove the columns\n",
    "titanic = titanic.drop(['deck', 'embark_town', 'alive', 'class', 'alone', 'adult_male', 'who'], axis=1)\n",
    "\n",
    "#Drop/remove the rows with missing values\n",
    "titanic = titanic.dropna(subset =['embarked', 'age'])\n",
    "\n",
    "#Note: Could've used .fillna() to fill in missing values for age like with the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the NEW number of rows and columns in the data set\n",
    "titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the data types to see which columns need to be transformed / encoded to a number\n",
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the unique values in the columns\n",
    "print(titanic['sex'].unique())\n",
    "print(titanic['embarked'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding categorical data values (Transforming object data types to integers)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "#Encode sex column\n",
    "titanic.iloc[:,2]= labelencoder.fit_transform(titanic.iloc[:,2].values)\n",
    "#print(labelencoder.fit_transform(titanic.iloc[:,2].values))\n",
    "\n",
    "#Encode embarked\n",
    "titanic.iloc[:,7]= labelencoder.fit_transform(titanic.iloc[:,7].values)\n",
    "#print(labelencoder.fit_transform(titanic.iloc[:,7].values))\n",
    "\n",
    "#Print the NEW unique values in the columns\n",
    "print(titanic['sex'].unique())\n",
    "print(titanic['embarked'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the NEW data types\n",
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into independent 'X' and dependent 'Y' variables\n",
    "X = titanic.iloc[:, 1:8].values #Notice I started from index  1 to 7, essentially removing the first column\n",
    "Y = titanic.iloc[:, 0].values #Get the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into 80% Training set and 20% Testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data to bring all features to the same level of magnitude\n",
    "# This means the data will be within a specific range for example 0 -100 or 0 - 1\n",
    "\n",
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function within many Machine Learning Models\n",
    "def models(X_train,Y_train):\n",
    "  \n",
    "  #Using Logistic Regression Algorithm to the Training Set\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "  log = LogisticRegression(random_state = 0)\n",
    "  log.fit(X_train, Y_train)\n",
    "  \n",
    "  #Using KNeighborsClassifier Method of neighbors class to use Nearest Neighbor algorithm\n",
    "  from sklearn.neighbors import KNeighborsClassifier\n",
    "  knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "  knn.fit(X_train, Y_train)\n",
    "\n",
    "  #Using SVC method of svm class to use Support Vector Machine Algorithm\n",
    "  from sklearn.svm import SVC\n",
    "  svc_lin = SVC(kernel = 'linear', random_state = 0)\n",
    "  svc_lin.fit(X_train, Y_train)\n",
    "\n",
    "  #Using SVC method of svm class to use Kernel SVM Algorithm\n",
    "  from sklearn.svm import SVC\n",
    "  svc_rbf = SVC(kernel = 'rbf', random_state = 0)\n",
    "  svc_rbf.fit(X_train, Y_train)\n",
    "\n",
    "  #Using GaussianNB method of naïve_bayes class to use Naïve Bayes Algorithm\n",
    "  from sklearn.naive_bayes import GaussianNB\n",
    "  gauss = GaussianNB()\n",
    "  gauss.fit(X_train, Y_train)\n",
    "    \n",
    "  #Using DecisionTreeClassifier of tree class to use Decision Tree Algorithm\n",
    "  from sklearn.tree import DecisionTreeClassifier\n",
    "  tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "  tree.fit(X_train, Y_train)\n",
    "\n",
    "  #Using RandomForestClassifier method of ensemble class to use Random Forest Classification algorithm\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "  forest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "  forest.fit(X_train, Y_train)\n",
    "  \n",
    "  #print model accuracy on the training data.\n",
    "  print('[0]Logistic Regression Training Accuracy:', log.score(X_train, Y_train))\n",
    "  print('[1]K Nearest Neighbor Training Accuracy:', knn.score(X_train, Y_train))\n",
    "  print('[2]Support Vector Machine (Linear Classifier) Training Accuracy:', svc_lin.score(X_train, Y_train))\n",
    "  print('[3]Support Vector Machine (RBF Classifier) Training Accuracy:', svc_rbf.score(X_train, Y_train))\n",
    "  print('[4]Gaussian Naive Bayes Training Accuracy:', gauss.score(X_train, Y_train))\n",
    "  print('[5]Decision Tree Classifier Training Accuracy:', tree.score(X_train, Y_train))\n",
    "  print('[6]Random Forest Classifier Training Accuracy:', forest.score(X_train, Y_train))\n",
    "  \n",
    "  return log, knn, svc_lin, svc_rbf, gauss, tree, forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get and train all of the models\n",
    "model = models(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the confusion matrix and accuracy for all of the models on the test data\n",
    "#Classification accuracy is the ratio of correct predictions to total predictions made.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "for i in range(len(model)):\n",
    "  cm = confusion_matrix(Y_test, model[i].predict(X_test))\n",
    "\n",
    "  #extracting true_positives, false_positives, true_negatives, false_negatives\n",
    "  TN, FP, FN, TP = confusion_matrix(Y_test, model[i].predict(X_test)).ravel()\n",
    "\n",
    "  print(cm)\n",
    "  print('Model[{}] Testing Accuracy = \"{} !\"'.format(i,  (TP + TN) / (TP + TN + FN + FP)))\n",
    "  print()# Print a new line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the importance of the features\n",
    "forest = model[6]\n",
    "importances = pd.DataFrame({'feature':titanic.iloc[:, 1:8].columns,'importance':np.round(forest.feature_importances_,3)})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the importance\n",
    "importances.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Prediction of Random Forest Classifier model\n",
    "pred = model[6].predict(X_test)\n",
    "print(pred)\n",
    "\n",
    "#Print a space\n",
    "print()\n",
    "\n",
    "#Print the actual values\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the data points would I have survived ? \n",
    "# Most likely I would've been in 3rd class (pclass = 3), Im a male (sex = 1), age is older than 18 (age = 21), no siblings onboard (sibsp = 0), \n",
    "#no parents or children (parch =0), fare the minimum price (fare = 0), embarked queens town = (embarked =1)\n",
    "my_survival = [[3,1,21,0, 0, 0, 1]]\n",
    "\n",
    "#uncomment to see all of the models predictions\n",
    "#for i in range(len(model)):\n",
    "#  pred = model[i].predict(my_survival)\n",
    "#  print(pred)\n",
    "\n",
    "\n",
    "#Print Prediction of Random Forest Classifier model\n",
    "pred = model[6].predict(my_survival)\n",
    "print(pred)\n",
    "\n",
    "if pred == 0:\n",
    "  print('Oh no! You didn’t make it')\n",
    "else:\n",
    "  print('Nice! You survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
